{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\goelp\\Anaconda3\\envs\\py35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "x_train shape: (8000, 28, 28, 1)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 2052      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 591,844\n",
      "Trainable params: 591,844\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - 354s 44ms/step - loss: 0.8332 - acc: 0.6406\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - 352s 44ms/step - loss: 0.5779 - acc: 0.7586\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - 392s 49ms/step - loss: 0.4735 - acc: 0.8121\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - 369s 46ms/step - loss: 0.4244 - acc: 0.8342\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 385s 48ms/step - loss: 0.3758 - acc: 0.8480\n",
      "[0 2 3 6]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import math\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.layers import Input\n",
    "\n",
    "\n",
    "filename1='train_image.pkl'\n",
    "\n",
    "with open(filename1,\"rb\") as f:\n",
    "    train_data=pickle.load(f)\n",
    "\n",
    "filename2='train_label.pkl'\n",
    "\n",
    "with open(filename2,\"rb\") as f:\n",
    "    train_label=pickle.load(f)    \n",
    "    \n",
    "    \n",
    "filename3='test_image.pkl'\n",
    "with open(filename3,\"rb\") as f:\n",
    "    test_data=pickle.load(f)    \n",
    "    \n",
    "    \n",
    "#i1=data[0]\n",
    "#i1=np.asarray(i1)\n",
    "X_train=[]\n",
    "for i in range(0,len(train_data)):\n",
    "    X_train.append(train_data[i])\n",
    "    \n",
    "X_label=[]\n",
    "for i in range(0,len(train_label)):\n",
    "    X_label.append(train_label[i])\n",
    "\n",
    "X_test=[]\n",
    "for i in range(0,len(test_data)):\n",
    "    X_test.append(test_data[i])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "2->1\n",
    "3->2\n",
    "6->4\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "X_label=[1 if x==2 else x for x in X_label]\n",
    "X_label=[2 if x==3 else x for x in X_label]\n",
    "X_label=[3 if x==6 else x for x in X_label]\n",
    "\n",
    "X_label = to_categorical(X_label)\n",
    "\n",
    "\n",
    "X_train=np.asarray(X_train)\n",
    "X_test=np.asarray(X_test)\n",
    "\n",
    "X_label=np.asarray(X_label)\n",
    "\n",
    "\n",
    "def unique(list1): \n",
    "    x = np.array(list1) \n",
    "    print(np.unique(x)) \n",
    "\n",
    "#unique classes    \n",
    "unique(X_label)\n",
    "\n",
    "num_classes=4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "\n",
    "X_test /= 255\n",
    "\n",
    "print('x_train shape:', X_train.shape)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\"\"\"\n",
    "\n",
    "batch_size=160\n",
    "epochs=5\n",
    "   \n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))\n",
    "model.add(Activation('relu'))\n",
    "BatchNormalization(axis=-1)\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "BatchNormalization(axis=-1)\n",
    "model.add(Conv2D(64,(3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "BatchNormalization(axis=-1)\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "# Fully connected layer\n",
    "\n",
    "BatchNormalization()\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "BatchNormalization()\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(4))\n",
    "\n",
    "# model.add(Convolution2D(10,3,3, border_mode='same'))\n",
    "# model.add(GlobalAveragePooling2D())\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(X_train, X_label,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,shuffle=True)\n",
    "\n",
    "from array import *\n",
    "def array_list(array_num): \n",
    "    num_list = array_num.tolist() # list \n",
    "    return num_list \n",
    "\n",
    "pred=model.predict(X_test)\n",
    "\n",
    "\n",
    "pred_metrics=array_list(pred)\n",
    "\n",
    "\n",
    "max_v=0\n",
    "\n",
    "pred_final=[]\n",
    "pred_final_value=[]\n",
    "for i in range(0,len(pred_metrics)):\n",
    "    max_v=0\n",
    "    max_v_index=0\n",
    "    for j in range(0,len(pred_metrics[i])):\n",
    "        if pred_metrics[i][j]>max_v:\n",
    "            max_v=pred_metrics[i][j]\n",
    "            max_v_index=j\n",
    "    pred_final_value.append(max_v)\n",
    "    pred_final.append(max_v_index)\n",
    "\n",
    "        \n",
    "\"\"\"\n",
    "2->1\n",
    "3->2\n",
    "6->4\n",
    "\"\"\"\n",
    "\n",
    "pred_final=[6 if x==3 else x for x in pred_final]\n",
    "pred_final=[3 if x==2 else x for x in pred_final]\n",
    "pred_final=[2 if x==1 else x for x in pred_final]\n",
    "\n",
    "unique(pred_final)\n",
    "\n",
    "\n",
    "index=[]\n",
    "for i in range(0,2000):\n",
    "    index.append(i)\n",
    "\n",
    "\n",
    "output=list(zip(index, pred_final))\n",
    "\n",
    "\n",
    "import csv\n",
    "\n",
    "\n",
    "with open('parth_goel.csv', 'w') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerows(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\goelp\\Desktop\\Computer Vision\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\goelp\\Desktop\\Computer Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
